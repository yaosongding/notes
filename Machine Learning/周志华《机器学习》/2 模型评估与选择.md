---
typora-root-url: ../../../notes
---

# 模型评估与选择

## 过拟合与欠拟合

需要注意的一点是，欠拟合通常比较好解决，但是欠拟合确实日常学习任务中的障碍。各类学习算法中必然带有一些针对过拟合的措施。

## P问题与NP问题

P问题：能用多项式时间算法计算得到结果的问题，称为多项式问题。

NP问题：Non-deterministic Polynomial，这类问题是指，即使你得到了问题的解，我要验证你的解是否正确，我验证所花的时间是**多项式**，至于求解本身所花的时间是否是多项式我不管，可能有多项式算法，可能没有，也可能是不知道，这类问题称为NP问题。

**P肯定是NP，但是NP到底是不是P，是尚未解决的世界难题**

（参考[https://blog.csdn.net/bitcarmanlee/article/details/51935400](https://blog.csdn.net/bitcarmanlee/article/details/51935400)）

## 对学习效果的评估方法

* 需要注意的是，训练和测试集的划分要保持数据分布的一致，避免导致因数据划分而导致的误差。如分类任务中至少要保持两个集合的各类别样本比例一致（分层采样）。

* 在使用2.2.1提到的**留出法**时，为了进一步消除划分集合导致的误差，要进行若干次随机划分，重复实验，取综合结果

* **交叉验证法。**所有的样本都会充当一次测试数据。示意图十分关键，摘抄如下：![](/assets/cross_validation.png)

* **bootstrap**（自助法）也是一个非常常用的评估方法, 简单来说就是有放回的抽样。值得注意的是一个样本在m次采样中始终不被采到的概率是  
  ![](/assets/bootstrap_method.png)

* **优缺点总结：**

  ![image-20181204110821598](/Machine Learning/周志华《机器学习》/assets/image-20181204110821598-3892901.png)

  简单来说，一般使用的就是留出法

- 关于调参：

  - 很多学习算法的参数是在实数范围内取值，因此在调参时只能是，对每一个参数确定一个调节的步长，在一定范围内每次增减步长来调节参数。

  - 即使是上面的情况，调参还是很困难。m个参数，每个参数可取的值有n个，则有$m ^ n$个模型需要考察。调参也是机器学习任务中的一个关键

  - 最后的重要步骤，在模型选择完成后，应该用整个数据集重新训练模型，然后提交给用户：

    ![image-20181204111952939](/Machine Learning/周志华《机器学习》/assets/image-20181204111952939-3893592.png)

  - 分清训练集，验证集和测试集

- 关于**性能度量**

  - **回归任务**常用均方误差，然后作者展开讲了**分类任务**的性能度量
  - 准确率和召回率
    - 准确率（查准率）：在你认为是真的样本中，有多少是真样本
    - 召回率（查全率）：所有的真样本中，你挑出了多少
    - 书中给这两个概念时使用的是二分类问题（**混淆矩阵**）举例，而在**多分类**问题中，可以单独对每个类定义真样本和假样本，（即对每个类变成一个二分类问题）单独算出每个类的准确率和召回率
    - 通常，准确率高的时候召回率偏低，反之亦然。作者举了生动的例子来说明这个问题
    - P-R图是怎么画的，作者有明确的说明
    - **为什么P-R曲线的面积可以作为学习器优劣的标准**。试想一些极限情况，比如：P-R曲线和X-Y轴形成一个正方形，这个时候效果肯定是最好的，面积也是最大的
    - “平衡点（**BEP**）”标准比较A和B的优劣：平衡点越大，学习器越好；因为用BEP相当于估算了P-R曲线下面积
    - **F1**度量和$F_\beta$,作者对两者做了详细的解读，并解读了$\beta$的意义
    - 对同一个问题中多个混淆矩阵的度量

  - **ROC和AUC**

    - auc（area under roc curve）是roc曲线下的面积
    - 细致分析一下roc图的画法，再分析，可以理解公式2.22，注意，若一个正例和一个反例的预测结果（分数）相同，则他们各有50%的概率排在对方前面，这也是2.21中 1/2的来历

  - 代价曲线

    - 非均等代价下，ROC不再可用，但是可以用“代价曲线”
